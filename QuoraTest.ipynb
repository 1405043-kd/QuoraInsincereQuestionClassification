{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quoraProject.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1405043-kd/QuoraInsincereQuestionClassification/blob/master/QuoraTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uC5-InTY0GNi",
        "colab_type": "code",
        "outputId": "d819f2d7-a1e0-40b1-bfeb-628de07ac58c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uy7ahA2H0y0n",
        "colab_type": "code",
        "outputId": "9c51f5cf-17b6-4551-9cbf-ef3a179ba4b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-04 06:37:43--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2019-02-04 06:37:43--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  20.8MB/s    in 1m 59s  \n",
            "\n",
            "2019-02-04 06:39:42 (17.5 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3wrDn1ydA8-6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zipRef=zipfile.ZipFile('glove.840B.300d.zip','r')\n",
        "zipRef.extractall()\n",
        "zipRef.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eyo4w0E_BAyS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "trainDf=pd.read_csv(\"/content/gdrive/My Drive/colabData/MlProject/train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ToMTqRi4BP0u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oWH53R7uBkb5",
        "colab_type": "code",
        "outputId": "63d840da-5930-41c4-fc61-e0936932ff53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "def readEmbeddings(embeddingsFile):\n",
        "    \n",
        "    tempDict={}\n",
        "    f=open(embeddingsFile)\n",
        "    for line in tqdm(f):\n",
        "        values=line.split(\" \")\n",
        "        word=values[0]\n",
        "        vect=np.asarray(values[1:],dtype='float32')\n",
        "        tempDict[word]=vect\n",
        "    f.close()\n",
        "   \n",
        "    return tempDict\n",
        "embeddingsDict=readEmbeddings('glove.840B.300d.txt')\n",
        "\n",
        "vectDim=300\n",
        "numOfVect=30\n",
        "len(embeddingsDict['the'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2196017it [02:56, 12419.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "e_cCFCIdCYHo",
        "colab_type": "code",
        "outputId": "5c1b5d22-5cba-4776-f00a-eec82e538be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "def textToArr(txt):\n",
        "    zeroVect=np.zeros(vectDim)\n",
        "    txt=txt[:-1].split()[:numOfVect]\n",
        "    embeds=[embeddingsDict.get(x,zeroVect) for x in txt]\n",
        "    embeds+=[zeroVect]*(numOfVect-len(embeds)) \n",
        "    return np.array(embeds)\n",
        "\n",
        "textToArr(\"what is quora?\").shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "p7wFIETnCcHc",
        "colab_type": "code",
        "outputId": "7b7787dd-d421-408c-dd9b-5d388d9188c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "trainDf=trainDf[:300000]\n",
        "trainDf, valDf = train_test_split(trainDf, test_size=0.2, random_state=42)\n",
        "valDf, testDf = train_test_split(valDf, test_size=0.5, random_state=42)\n",
        "print(trainDf.shape)\n",
        "print(testDf.shape)\n",
        "print(valDf.shape) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(240000, 3)\n",
            "(30000, 3)\n",
            "(30000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YGaopnLtDLU8",
        "colab_type": "code",
        "outputId": "680e776a-ae11-475a-e52c-8387c69408a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#valVects = np.array([textToArr(x) for x in tqdm(valDf[\"question_text\"])])\n",
        "valY = np.array(valDf[\"target\"])\n",
        "tempLst=[]\n",
        "for x in tqdm(valDf[\"question_text\"]):\n",
        "    try:\n",
        "        tempLst.append(textToArr(x))\n",
        "    except:\n",
        "        pass\n",
        "valVects=np.array(tempLst)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30000/30000 [00:02<00:00, 13758.67it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nKMKRQxLFoPh",
        "colab_type": "code",
        "outputId": "e1e57313-c20f-4bde-c1ec-8d2898cb61a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#testVects = np.array([textToArr(x) for x in tqdm(testDf[\"question_text\"])])\n",
        "#testY = np.array(testDf[\"target\"])\n",
        "\n",
        "testY = np.array(testDf[\"target\"])\n",
        "tempLst1=[]\n",
        "for x in tqdm(testDf[\"question_text\"]):\n",
        "    try:\n",
        "        tempLst1.append(textToArr(x))\n",
        "    except:\n",
        "        pass\n",
        "testVects=np.array(tempLst1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30000/30000 [00:02<00:00, 13742.53it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Oq8TTHDEHFZh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batchSize = 128\n",
        "\n",
        "def batchGenerate(train_df):\n",
        "    numBatches = math.ceil(len(train_df) / batchSize)\n",
        "    while True: \n",
        "        train_df = train_df.sample(frac=1.)   \n",
        "        for i in range(numBatches):\n",
        "            texts = train_df.iloc[i*batchSize:(i+1)*batchSize, 1]\n",
        "            textArr = np.array([textToArr(text) for text in texts])\n",
        "            yield textArr, np.array(train_df[\"target\"][i*batchSize:(i+1)*batchSize])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xedJCQORHJDH",
        "colab_type": "code",
        "outputId": "1c60653b-6ca4-4610-cb26-4fe2801047da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import CuDNNLSTM, Dense, Bidirectional, Dropout\n",
        "#from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "D9J8tcQhHLhT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred): \n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred): \n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b7GgMUm9HOvX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True), input_shape=(30, 300)))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(CuDNNLSTM(64)))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1])\n",
        "\n",
        "#plot_model(model,to_file='modelplot.png',show_shapes=True,show_layer_names=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EZWnBWYhLuPl",
        "colab_type": "code",
        "outputId": "5a4cc2c5-62f2-4b3e-d94a-cde66f32e809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_1 (Bidirection (None, 30, 128)           187392    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 128)               99328     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 286,849\n",
            "Trainable params: 286,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3ZIwE1dLHWgD",
        "colab_type": "code",
        "outputId": "10d8a1e6-0e96-4feb-fc85-d741cfaca3e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        }
      },
      "cell_type": "code",
      "source": [
        "bg = batchGenerate(trainDf)\n",
        "model.fit_generator(bg, epochs=20, steps_per_epoch=1000, validation_data=(valVects, valY), verbose=True) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1000/1000 [==============================] - 60s 60ms/step - loss: 0.1339 - acc: 0.9497 - f1: 0.4546 - val_loss: 0.1288 - val_acc: 0.9475 - val_f1: 0.5889\n",
            "Epoch 2/20\n",
            "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1196 - acc: 0.9527 - f1: 0.5272 - val_loss: 0.1170 - val_acc: 0.9547 - val_f1: 0.5610\n",
            "Epoch 3/20\n",
            "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1142 - acc: 0.9553 - f1: 0.5650 - val_loss: 0.1137 - val_acc: 0.9562 - val_f1: 0.5444\n",
            "Epoch 4/20\n",
            "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1085 - acc: 0.9579 - f1: 0.5936 - val_loss: 0.1120 - val_acc: 0.9559 - val_f1: 0.5905\n",
            "Epoch 5/20\n",
            "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1088 - acc: 0.9575 - f1: 0.5951 - val_loss: 0.1109 - val_acc: 0.9566 - val_f1: 0.6071\n",
            "Epoch 6/20\n",
            "1000/1000 [==============================] - 55s 55ms/step - loss: 0.1011 - acc: 0.9602 - f1: 0.6351 - val_loss: 0.1103 - val_acc: 0.9563 - val_f1: 0.6078\n",
            "Epoch 7/20\n",
            "1000/1000 [==============================] - 56s 56ms/step - loss: 0.1003 - acc: 0.9605 - f1: 0.6246 - val_loss: 0.1104 - val_acc: 0.9575 - val_f1: 0.5912\n",
            "Epoch 8/20\n",
            "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0949 - acc: 0.9623 - f1: 0.6436 - val_loss: 0.1114 - val_acc: 0.9556 - val_f1: 0.5896\n",
            "Epoch 9/20\n",
            "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0902 - acc: 0.9642 - f1: 0.6722 - val_loss: 0.1143 - val_acc: 0.9573 - val_f1: 0.5899\n",
            "Epoch 10/20\n",
            "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0940 - acc: 0.9622 - f1: 0.6600 - val_loss: 0.1106 - val_acc: 0.9577 - val_f1: 0.5952\n",
            "Epoch 11/20\n",
            "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0801 - acc: 0.9687 - f1: 0.7168 - val_loss: 0.1147 - val_acc: 0.9554 - val_f1: 0.6023\n",
            "Epoch 12/20\n",
            "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0831 - acc: 0.9669 - f1: 0.7052 - val_loss: 0.1165 - val_acc: 0.9568 - val_f1: 0.5992\n",
            "Epoch 13/20\n",
            "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0746 - acc: 0.9706 - f1: 0.7349 - val_loss: 0.1234 - val_acc: 0.9544 - val_f1: 0.6099\n",
            "Epoch 14/20\n",
            "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0714 - acc: 0.9718 - f1: 0.7463 - val_loss: 0.1220 - val_acc: 0.9532 - val_f1: 0.6066\n",
            "Epoch 15/20\n",
            "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0747 - acc: 0.9703 - f1: 0.7432 - val_loss: 0.1202 - val_acc: 0.9535 - val_f1: 0.6124\n",
            "Epoch 16/20\n",
            "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0580 - acc: 0.9772 - f1: 0.8023 - val_loss: 0.1348 - val_acc: 0.9510 - val_f1: 0.5988\n",
            "Epoch 17/20\n",
            "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0622 - acc: 0.9758 - f1: 0.7896 - val_loss: 0.1332 - val_acc: 0.9544 - val_f1: 0.5913\n",
            "Epoch 18/20\n",
            "1000/1000 [==============================] - 56s 56ms/step - loss: 0.0550 - acc: 0.9788 - f1: 0.8131 - val_loss: 0.1569 - val_acc: 0.9523 - val_f1: 0.5621\n",
            "Epoch 19/20\n",
            "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0501 - acc: 0.9808 - f1: 0.8321 - val_loss: 0.1593 - val_acc: 0.9522 - val_f1: 0.5574\n",
            "Epoch 20/20\n",
            "1000/1000 [==============================] - 55s 55ms/step - loss: 0.0534 - acc: 0.9795 - f1: 0.8250 - val_loss: 0.1554 - val_acc: 0.9530 - val_f1: 0.5861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f01bfa1f940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "gkRHaqbILw2m",
        "colab_type": "code",
        "outputId": "9f1ce5ff-d6e6-4718-9881-6039fc8c197c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(testVects, testY, batch_size=1024, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40000/40000 [==============================] - 3s 87us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bh4VRBuQL91-",
        "colab_type": "code",
        "outputId": "ecfc2d64-a5ce-4269-8511-98ccbaa18589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "print(model.metrics_names[0],\":\",score[0])\n",
        "print(model.metrics_names[1],\":\",score[1])\n",
        "print(model.metrics_names[2],\":\",score[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss : 0.14998370048999787\n",
            "acc : 0.9546\n",
            "f1 : 0.6104958294868469\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}